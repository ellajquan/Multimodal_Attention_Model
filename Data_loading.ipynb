{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "import boto3\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "with open('config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Extract configuration parameters\n",
    "s3_bucket_name = config[\"s3_bucket_name\"]\n",
    "img_rows = config[\"img_rows\"]\n",
    "img_cols = config[\"img_cols\"]\n",
    "as_gray = config[\"as_gray\"]\n",
    "channels = config[\"in_channel\"]\n",
    "s3_train_path_prefix = config[\"s3_train_path_prefix\"]\n",
    "s3_test_path_prefix = config[\"s3_test_path_prefix\"]\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_from_s3(s3_key, as_gray=True):\n",
    "    \"\"\"Reads an image from S3 and returns it as a NumPy array.\"\"\"\n",
    "    obj = s3.get_object(Bucket=s3_bucket_name, Key=s3_key)\n",
    "    image = imread(BytesIO(obj['Body'].read()), as_gray=as_gray)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import boto3\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = config[\"s3_bucket_name\"]\n",
    "\n",
    "# Define the function to read and combine left and right images for each view\n",
    "def read_and_combine_views(left_paths, right_paths, img_rows, img_cols, as_gray, channels, bucket_name, prefix):\n",
    "    images_combined = []\n",
    "    for left_path, right_path in zip(left_paths, right_paths):\n",
    "        try:\n",
    "            # Load left image\n",
    "            left_s3_key = f\"{prefix}/{left_path}\"\n",
    "            left_obj = s3.get_object(Bucket=bucket_name, Key=left_s3_key)\n",
    "            left_image = imread(BytesIO(left_obj['Body'].read()), as_gray=as_gray)\n",
    "            if as_gray and channels == 3:\n",
    "                left_image = gray2rgb(left_image)\n",
    "            left_image = resize(left_image, (img_rows, img_cols), anti_aliasing=True)\n",
    "\n",
    "            # Load right image\n",
    "            right_s3_key = f\"{prefix}/{right_path}\"\n",
    "            right_obj = s3.get_object(Bucket=bucket_name, Key=right_s3_key)\n",
    "            right_image = imread(BytesIO(right_obj['Body'].read()), as_gray=as_gray)\n",
    "            if as_gray and channels == 3:\n",
    "                right_image = gray2rgb(right_image)\n",
    "            right_image = resize(right_image, (img_rows, img_cols), anti_aliasing=True)\n",
    "\n",
    "            # Stack left and right images along the last dimension\n",
    "            combined_image = np.stack((left_image, right_image), axis=-1)  # Shape: (img_rows, img_cols, channels * 2)\n",
    "            images_combined.append(combined_image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {left_path} or {right_path}: {e}\")\n",
    "    \n",
    "    # Convert to numpy array and normalize\n",
    "    images_combined = np.asarray(images_combined, dtype=np.float32)\n",
    "    images_combined = (images_combined - images_combined.min()) / (images_combined.max() - images_combined.min())\n",
    "    return images_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mg(file_paths, img_rows, img_cols, as_gray, channels, bucket_name, prefix):\n",
    "    images = []\n",
    "    s3 = boto3.client('s3')  # Reinitialize in case of multi-threading issues\n",
    "    for file_path in file_paths:\n",
    "        # Construct S3 key for the image\n",
    "        s3_key = f\"{prefix}/{file_path}\"\n",
    "        try:\n",
    "            # Load image from S3\n",
    "            obj = s3.get_object(Bucket=bucket_name, Key=s3_key)\n",
    "            image = imread(BytesIO(obj['Body'].read()), as_gray=as_gray)\n",
    "            \n",
    "            # Convert grayscale to RGB if necessary\n",
    "            if as_gray and channels == 3:\n",
    "                image = gray2rgb(image)\n",
    "            \n",
    "            # Resize image\n",
    "            image = resize(image, (img_rows, img_cols), anti_aliasing=True)\n",
    "            images.append(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {s3_key}: {e}\")\n",
    "    \n",
    "    # Convert to numpy array and normalize\n",
    "    images = np.asarray(images, dtype=np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
